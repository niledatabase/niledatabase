export const metadata = {
  title: "Distributed DDL at Global Scale",
  authors: ["gwenshap"],
  image: "2024-11-19-distributed-ddl/cover.webp",
  sizzle:
    "TBD",
  tags: ["database", "serverless", "postgres", "distributed systems"],
};

When we need to describe Nile in a single sentence, we say **"PostgreSQL re-engineered for multi-tenant apps"**. By multi-tenant apps, we mean applications like Stripe, Figma, Twilio, Notion, Workday, and Gusto - here a large number of customers is served from a shared application stack. In these types of applications, a key architectural challenge is deciding how to store data for each customer. 

Broadly speaking, there are two main approaches. The first is **database per tenant** (or sometimes **schema per tenant**):

![Database per tenant architecture](/blog/2024-11-19-distributed-ddl/db_per_tenant.png)

This architecture provides isolation and flexibility but requires more resources and effort to operate. 

The other approach is to place all tenants in the same shared schema and add a tenant identifier to every table:

![Shared schema for all tenants](/blog/2024-11-19-distributed-ddl/shared_schema.png)

This approach is simple and cost-effective, which is why most new applications start here. However, over time, it can run into scalability issues and difficulties in adapting to individual customer needs and requirements. 

That's why, no matter where you start, you eventually end up with a **hybrid model**. In a typical hybrid architecture, the database is distributed out through sharding. Most tenants are placed on shared shards, while larger and more demanding customers are allocated dedicated shards. 

Scale isn't the only reason to use the hybrid architecture. A more common reason is the need to store data in multiple regions. Tenants always prefer low latency, which requires data to be placed close to them or in a specific region. Some tenants also have compliance concerns that requires storing their data in specific countries.

Both hybrid and db-per-tenant architectures require a way to propagate the DDL changes to all the tenants instantaneously with great devex and high reliability.

Nile's model aims to provide the simple developer experience of shared schema while maintaining the isolation and flexibility of a database-per-tenant model. In our system, tenants are separated into **"virtual tenant databases"**. These virtual tenant databases can be placed on shared compute (which may be sharded depending on the workload), or on dedicated compute. Regardless of how the tenenant databases are organized, developers can work as if everything were in a single shared schema. 

![Nile virtual databases](/blog/2024-11-19-distributed-ddl/nile_virtual_databases.png)

Our goal is to support any number of virtual databases, distributed across a number of physical PostgreSQL instances, while still providing the seamless developer experience of a single schema shared by all tenants. **DDLs** (Data Definition Language commands) are SQL commands that modify the schema - things like `CREATE TABLE`, `ALTER TABLE` and `DROP INDEX`. Our goals for the developer experience with DDLs are:

* Each DDL applies to all tenants concurrently
* Behaves exactly as it normally would in Postgres. This includes supporting transactions with DDL and all the transactional guarantees (which we consider one of PostgreSQL's best features). It also includes performing the DDL synchronously from the user point of view, when the `CREATE TABLE` command returns, the table must be visible and usable for all tenants, regardless of their placement.
* The fact that each DDL executes over multiple virtual databases and physical instances should be completely transparent to developers

Let's dive into the architecture and implementation. We'll start with a high-level overview of the architecture and walk you through the green-path flow of executing a simple DDL. Then we'll dive into the details of how we solved the three most challenging problems with distributed DDLs: transactions, locks and failure handling. Along the way, we'll share some tips and tricks we used in building our Postgres extension -- these might come in handy if you decide to write your own extensions.

So, grab a coffee, and let's get started!

## Distributed DDL architecture walkthrough

We've implemented our distributed DDL system using two main components:
1. **`nile_ddl` extension:** This extension is loaded into every Postgres instance. It is responsible for intercepting DDL statements, extracting key information, and initiating the distributed transactions.
2. **Transaction coordinator:** This is a stand-alone service that distributes the DDL statements to all relevant databases and ensures that each DDL is either applied successfully to all databases or to none of them.

To understand how these components work together to execute a DDL statement, let's look at what happens when a user connects to their Nile database and issues a  `CREATE TABLE` command. This command is sent from the client to one of the Postgres instances, where it is intercepted by the `nile_ddl` extension. 

### Intercepting DDL with `processUtility_hook`

In order to intercept the DDL before it executes, `nile_ddl` uses the `processUtility_hook`. To understand why and how our extension uses this hook, we first need to explain what a utility command is and how PostgreSQL handles them. 

In Postgres terms, a "utility" is any command except `SELECT`, `INSERT`, `UPDATE` and `DELETE`. This includes all DDL commands as well as other commands like `COMMIT`, `NOTIFY` or `DO`. When Postgres recieves a utility command, it uses `ProcessUtility(..)` method to process it. This is a simple wrapper that looks like this:

```c
	if (ProcessUtility_hook)
		(*ProcessUtility_hook) (...);
	else
		standard_ProcessUtility(...);
```

This method checks if there are any extensions that want to process the utility command before Postgres runs its standard processing. The `nile_ddl` extension provides such a hook and, as a result, is called before Postgres processes any command. This is incredibly useful because `processUtility_hook` is triggered for nearly everything that isn't a SELECT or a DML, giving us a single entry point for almost everything we need to handle. 

Once we finished processing the command, it is our responsibility to call `standard_ProcessUtility`,  so that Postgres can continue its normal flow. A bit off-topic, but in case you're curious: `standard_ProcessUtility` method is essentially a gigantic switch statement that routes every one of the 60+ utility commands to their appropriate handler.

![Process utility hook](/blog/2024-11-19-distributed-ddl/process_utility_hook.png)

So, our extension gets called with a utility command. What happens next? At this point, it needs to perform a few tasks:

1. **Check that the command is one we want to handle** There are many utility commands and we only handle a subset. Commands that we don't handle, like `FETCH`, `SHOW` or `DISCARD` are just passed directly to  `standard_ProcessUtility`.
2. **Raise error for unsupported DDL.** Nile has specific restrictions on the type of relations we allow. For example, primary keys **must** include the `tenant_id` column, and `tablespace` commands are not supported at all (Nile handles these automatically). 
3. **Determine which locks the DDL requires.**
4. **Begin a distributed transaction** (only needed if this is the first DDL in a transaction)
5. **Ask the transaction coordinator to distribute the locks**

The reason we extract the locks and distribute them early in the process is to minimize the time spent holding a lock and reduce the risk of lock conflict. Most DDL statements require an `ACCESS EXCLUSIVE` lock, which not only prevents any queries from accessing the table in question while the DDL is executing but also prevents any new queries from accessing the table while the DDL is waiting to acquire the lock. To minimize the risk and the time spent while holding the lock, Nile attempts to acquire the necessary locks - with a short lock timeout - on all relevant databases before starting to execute the DDLs. If the lock acquisition fails on any database, the DDL will return an error rather than continue waiting for the lock.

Acquiring locks with a short timeout before executing DDLs is considered a best practice in Postgres for the reasons we just explained. Nile's distributed DDL implement this best practice for our users.

### Transaction coordinator

Once the `nile_ddl` extension determines the necessary locks, it calls the transaction coordinator to start a transaction (if necessary) and distribute the locks.

Starting the transaction is straightforward: the coordinator maintains open connections to all databases and simply sends each one a `BEGIN` command. 

Distributing the locks works similarly. The coordinator sends all databases the commands required to acquire the locks (more details in the section on locking). To avoid deadlocks, we ensure that locks are always acquired in the exact same order - both in terms of the sequence of databases and the order of locks within each database. This guarantees early failure in the event of conflicts and prevents situations where two concurrent transactions are each waiting for the other to release a lock on a different database.

![Distributing locks](/blog/2024-11-19-distributed-ddl/distribute_locks.png)

Once the locks are acquired, the `nile_ddl` extension instructs the coordinator to distribute the DDL itself. But first, it has to make sure the DDL is fully qualified. `CREATE TABLE todos (...)` can be ambigous - in which schema should Postgres create the table? This depends on the current `search_path` config and the existing schema, which can change on some databases while the DDL is distributed (for example, if there's a concurrect `CREATE SCHEMA` operation). To avoid an inconsistent result, `nile_ddl` modifies the DDL and makes sure all objects are fully qualified. Only then it sends the DDL to the transaction coordinator for distribution.

While the coordinator sends the DDL command to all other databases, the original extension that first received the DDL proceeds to call `standard_ProcessUtility` and process the DDL locally.

Meanwhile, each remote database receives the DDL command. Since every database runs our extension, these DDL commands are intercepted by the extension on each database. It is crucial that the extension does not attempt to redistribute these DDLs, as doing so would lead to an infinite loop. Therefore, the extension has to recognize that these DDLs were sent by the transaction coordinator and can be passed directly to `standard_ProcessUtility`. To achieve this, we use a configuration (GUC) set when the transaction coordinator initializes the transaction. This configuration indicates to the extension that it doesn't need to reprocess the DDLs that follow, as they have already been validated by the originating extension and distributed by the coordinator.

![Distributing DDL](/blog/2024-11-19-distributed-ddl/distribute_ddl.png)

Once all the databases finished processing the DDL, the coordinator notifies the originating extension of successful completion. The extension, which has already finished processing the DDL locally, can return the response to the client. At this point, we have successfully executed a distributed DDL. 

Or almost. We still need to commit the transaction. To maintain atomicity guarantees, it must commit on all databases or none at all. Let's look in detail at how we commit the distributed transaction.

## Transactions

You may recall from an earlier section that `BEGIN`, `COMMIT`, `ABORT` and `ROLLBACK` are all utility commands. So it might seem like we could handle transactions by having our `processUtility_hook` intercept these commands and implement distributed transactions. This approach is tempting, but it has some critical drawbacks:

- Intercepting every `BEGIN` will be very costly in a transaction-heavy database. Most of this effort will be wasted, as an OLTP system processes billions of DML transactions for every DDL. 
- Transactions can be implicit - standalone DDL statements are treated as transactions, for example. We won't always have a `BEGIN` to intercept, so we must treat each DDL as potentially starting a transaction.
- Intercepting a `COMMIT` only gives us a single point to intercept - when the `COMMIT` command is sent. However, distributed transactions require a two-phase commit, which can't be implemented with this single hook.

Fortunately, PostgreSQL provides a better mechanism for extensions to hook into the transaction lifecycle: `XactCallback` (pronounced "transaction callback").

This callback is triggered on various events within the transaction lifecycle, with an enum parameter that specifies which event occured. The events that we are interested in are:

- `XACT_EVENT_PRE_COMMIT` - This event occurs just before the commit itself. The callback method is allowed to return an error while processing it. If an error is returned, Postgres will abort the transaction and force a rollback. 
- `XACT_EVENT_COMMIT` - This event happens after the commit. At this point, the callback is not allowed to return an error. Regardless of what happened, it must reach a healthy and successful state since the client will recieve a confirmation that the transaction was successfully committed.
- `XACT_EVENT_ABORT` - This event is triggered when the transaction is aborted and the callback needs to handle the rollback.

The `nile_ddl` extension maps these events into a distributed two-phase commit (2PC) process.

The first task for the extension is to detect when to start a distributed transaction. This is simpler than it sounds: if `processUtility_hook` is called with a DDL and there's no currently active transaction in the same session, then the extension tells the transaction coordinator to begin a transaction. There's no scenario where a DDL is processed without an active transaction. If a transaction is already in progress for the session, the extension will continue to process all arriving DDLs. 

This process continues until `XactCallback` is triggered with `XACT_EVENT_PRE_COMMIT` event, which indicates that Postgres is preparing to commit the transaction. This callback is triggered regardless of whether there is an explicit transaction with an explicit `COMMIT` or  Postgres is committing an implicit transaction. The callback handles the pre-commit event by notifying the transaction coordinator and passing along the transaction ID.

The transaction coordinator then sends the `PREPARE TRANSACTION` command to all relevant databases.

![Prepare transaction flow](/blog/2024-11-19-distributed-ddl/prepare_xact.png)

According to the [Postgres documentation](https://www.postgresql.org/docs/current/sql-prepare-transaction.html), the `PREPARE TRANSACTION` behaves as follows:

> `PREPARE TRANSACTION` prepares the current transaction for two-phase commit. After this command, the transaction is no longer associated with the current session; instead, its state is fully stored on disk, and there is a very high probability that it can be committed successfully, even if a database crash occurs before the commit is requested.  
> Once prepared, a transaction can later be committed or rolled back with `COMMIT PREPARED` or `ROLLBACK PREPARED`, respectively. Those commands can be issued from any session, not only the one that executed the original transaction.

The phrase "very high probability that it can be committed successfully" may sound a bit less reassuring than we'd like. In practice, it means that `PREPARE TRANSACTION` is successful when it has persisted the transaction state to disk. The transaction will be committed successfully unless the database crashes **and** the files or disks where it is stored are completely lost. If this happens, it is likely that much more than just this one transaction is lost. In other scenarios, such as running out of memory, the "prepared" state is preserved and the transaction can be committed if `COMMIT PREPARED` is retried, even from other sessions. 

Barring this very rare scenario, `PREPARE TRANSACTION` has all the properties we need from the first phase of two-phase commit: It is durable, and the prepared transaction can be committed or rolled back from any session. This ensures that once we successfully prepared transactions on all databases, we can reach a consistent state no matter what else happens. Additionally, if `PREPARE TRANSACTION` fails, it will automatically trigger a rollback on the database where it failed. 

Let's assume that all databases successfully prepared their transactions for commit (we'll cover the failure scenarios in the next section). This succesful preparation completes the first phase of the two-phase commit (2PC). The `XactCallback` on the originating database will then return successfully, allowing Postgres to proceed with the transaction commit. The `XactCallback` will be triggered once more, this time with `XACT_EVENT_COMMIT` event. During this phase, the first action the `nile_ddl` extension takes is to reset its state - such as cleaning up the transaction in progress - so that the next DDL command will begin a new transaction. This cleanup comes first to simplify error handling. Then the extension commits the transaction locally and instructs the transaction coordinator to send the `COMMIT PREPARED` command to all databases, which commits all the prepared transactions in the remote databases.

![Commit prepared transaction flow](/blog/2024-11-19-distributed-ddl/prepare_xact.png)

Once all the databases commit, the second phase of the 2PC is completed, and the distributed transaction is fully committed. We still need to discuss what happens if they don't commit successfully. But before diving into that, lets take a quick detour and look at how we handle locks.

## Locks

If you recall back, the first step the `nile_ddl` takes toward distributing a DDL, is to determine the locks the DDL will need and attempt to acquire them on all relevant databases. We do this with 3 simple goals in mind:

1. **Fail early:** If a DDL is going to fail due to inability to acquire locks, we want to know about this before performing any resource intensive operations.
2. **Don't block for too long:** Many DDLs require `ACCESS EXCLUSIVE` lock. Attempts to acquire this lock will block other sessions, even while waiting for the lock to get acquired. On a busy OLTP system it is important to minimize such blocks.
3. **Don't deadlock:** We want to avoid a situation where two sessions are stuck, each waiting for the other to release a lock and both failing to make progress. 

In order to fail early, we make sure to acquire all the necessary locks as the first step in processing a DDL. Before we even run the DDL locally. We could do it in parallel, but this can be very wasteful - imagine building an index on a large table locally, only to roll it back because we couldn't acquire the lock on a table on one of the remote databases. 

So the `nile_ddl` extension takes the DDL and tries to determine which locks it will need. `ALTER` and `DROP` are fairly straight forward, we need to acquire a lock on the objects that the DDL is modifying (`DROP CASCADE` can be more complex since we need to determine all dependent objects and lock them too). In most cases, acquiring the lock is simply a matter of sending `LOCK TABLE <table name> IN <lock level> MODE` with the same level that the DDL will require later. So before distributing `DROP TABLE todos`, the transaction coordinator must distribute `LOCK TABLE todos ACCESS EXLUSIVE MODE`. However, `LOCK TABLE` only applies to... well, tables. And we sometimes need to lock other objects. For example `DROP SCHEMA` requires locking the schema. Postgres has internal methods for locking other objects, so in our extension, we added the following logic:

```c
	if (is_rel)
		LockRelationOid(objid, lockmode);
	else
		LockDatabaseObject(classid, objid, objsubid, lockmode);
```

If we need to lock a relation such as a table or a view, we use `LockRelationOid`, the Postgres method behind `LOCK TABLE`. If we need to lock another object, we use `LockDatabaseObject` and directly lock the object we need.

This is simple enough when acquiring locks locally, but how do we distribute this logic? We wrapped the object lock acquisition logic in the `nile_ddl` extension in a function and then exported it as a function:

```c
PGDLLEXPORT Datum nile_ddl_objectlock(PG_FUNCTION_ARGS);

PG_FUNCTION_INFO_V1(nile_ddl_objectlock);
```

Then the transaction coordinator can send `SELECT nile_ddl.nile_ddl_objectlock(...)` to all the databases and acquire all the necessary locks for the DDL.

When the transaction coordinator distributes the actual DDL, Postgres will try to re-acquire the locks. Because the DDL execution will happen in the same session in which we acquired the locks initially, and the locks are on the same objects and with the same level, we are guaranteed that the DDL processing will successfully acquire these locks. 

So far we dealt with acquiring locks on existing tables and other objects. But there is one other case we need to handle before we are done. `CREATE TABLE` also requires locks - in order to avoid conflict between two sessions attempting to create the same table. How can we lock a table that does not exist yet? 

Normally Postgres uses the data dictionary for this. It inserts a row for this new table into several tables in pg_catalog, the table name is added to unique indexes, and any attempt to insert another row with the same name into the same unique index will first block and then fail after the first session commits. Unfortunately, we can't use the same method. Row locks behave differently from table locks - they can't get re-acquired. Which means that if we manage to successfully acquire such lock, the actual DDL will then block on the same lock. 

Another option would be to use an "advisory lock". These are locks not enforced by Postgres itself, but they can be acquired and used by application logic. However, our users may be using advisory locks, and unlike other lock types, they don't have namespaces - each advisory lock is identified by its ID only. This creates a risk of collision - where we need to use an advisory lock with an ID that one of our users is also using. It will be a bit weird if some part of the application will block when someone creates tables.

To resolve this, we dove deep into the implementation of locks inside Postgres. All the locks we discussed so far - table locks, object locks, advisory locks - they all use the lower level `LockAcquire` method. This method signature is:

```c
extern LockAcquireResult LockAcquire(const LOCKTAG *locktag,
									 LOCKMODE lockmode,
									 bool sessionLock,
									 bool dontWait);
```

The first parameter, `LOCKTAG` is a struct identifies the "thing" we are locking. This includes the type of lock and then 4 integers with more specific identifiers. Their meaning depend on the type of lock - these can be object ID, block number, row id, transaction ID, etc.

If you look at the enum for the type of locks, you'll see:

```c
typedef enum LockTagType
{
	LOCKTAG_RELATION,			/* whole relation */
	... /* left out more locks, check the PG source code for details */
	LOCKTAG_USERLOCK,			/* reserved for old contrib/userlock code */
	LOCKTAG_ADVISORY			/* advisory user locks */
} LockTagType;
```

See the `USERLOCK` type? It is reserved, but no longer used. So we will use it. We'll use the 4 fields in `LOCKTAG` to identify the table with database ID, schema ID and a hash of the table name (since an integer isn't enough space for the actual name):

```c
locktag.locktag_type = LOCKTAG_USERLOCK;

locktag.locktag_field1 = logical_db_id;
locktag.locktag_field2 = schema_name_hash;
locktag.locktag_field3 = object_name_hash;

res = LockAcquire(&locktag,AccessExclusiveLock…);
```

And just like we did for previous locks, we wrapped the code that acquires the user locks in a method that we then exposed as part of the `nile_ddl` extension. Before distributing `CREATE TABLE todos()` the transaction coordinator has to distribute `SELECT nile_ddl.nile_ddl_userlock(...)` which acquire the user locks which we hold for the table creation.

In order to avoid lock contention, long blocking and deadlock we take few safety precautions in addition to the early lock acquisition:
- We acquire locks in the same order on all databases
- We always start acquiring locks with the same database, so there won't be distributed conflicts and local conflicts will be detected early
- We set `LOCK_TIMEOUT` to a low value before executing anything related to distributed DDLs

Even with all the precautions, things can still go wrong. In the next section we'll discuss our failure handling mechanisms.

## When things go wrong

Failure handling in distributed systems has to be built into every part of the architecture, it can't be added of as an afterthought. This is why we oriented our architecture around tried-and-true transaction handling - Postgres transaction mechanism and 2PC. The architecture provides the basic primitives for handling failure scenarios safely. In this section we'll look into key failure scenarios and how we used the components described above to deal with these scenarios.

If you were to start listing out all the failure scenarios - the state of the database, the type of failures that can occure and the possible ways to handle each, you'll end up with a rather intimidating list. We went through this exercise and listed dozens of possible scenarios. This list is useful both to make sure we are thinking comprehensively, and also later on when it comes time to test our handling of all these scenarios.

By examining all the failure scenarios, we derived two key insights that guided our design.

The first insight is that there are two distinct types of failures: Failures that happen before the `PRECOMMIT` phase succeeds, which always result in `ROLLBACK` and failures that happen after and will always result in `COMMIT`.

The transition happens when all databases respond to the `PREPARE TRANSACTION` command from the transaction coordinator.  We consider the responses to `PREPARE TRANSACTION` as votes from each database on the decision to commit. This to be a unanimous decision - if any database returns an error, we will force everyone to roll back with `ROLLBACK PREPARED` command. If every database responded successfully, we have a successful vote to commit, everyone is committed to commit the transaction. At this point, we say that the commit is **"doomed to succeed"**, as per Postgres we can no longer return errors or roll back.

The second insight is that all types of database failures result in a database failing to respond to the transaction coordinator for longer than a set timeout value. This isn't a new insight - this is a classic result in distributed systems. The insight is that this failure to communicate leads to a transaction in an unknown state - did the faulty database prepare the transaction? rolled it back? committed? We can't know until we can get a response from the database again. Therefore the first step in handling failure scenarios is to determine the current state of the system.

In order to resolve the state of transactions, we reconcile information from several sources:
- `pg_prepared_xact` - This is where Postgres stores the state of prepared transactions. Every transaction in this table was successfully prepared but not yet committed. 
- `distributed_transactions` - This is a table that Nile maintains on each database. We insert and update it as part of each DDL transaction. Rows here are only visible by other sessions after the transaction committed successfully, as part of Postgres' ACID guarantees which only allow reading committed rows. In addition, we have a table by that name on a separate database (called "metadata database"), which centralizes the state of all transactions for fast lookup. The `distributed_transactions` table on each database is a source of truth, as its integrity is guaranteed by Postgres. The centralized table is maintained with "best effort" and isn't guaranteed to be 100% up to date at any point. 
- `dist_tx_participants` - This table is also in the metadata database. This table tracks the state of each transaction for each participating database in a central location. It isn't guaranteed to always have the latest state. Therefore we use this table as an optimization, but we also check individual databases for newer information.
- Transaction Coordinator in-memory state - The transaction coordinator maintains an in-memory cache with all the connections to the databases, the transaction IDs of active transactions and the status of these transactions. Unlike the other sources of information, this information is not persisted - if the coordinator crashes, we will recover this state from the other sources.

Note that we use the existing implementation of transactions and ACID in Postgres to make sure we have all the state information that we need, persisted in the database. Postgres provides us with the basic primitives of atomicity, isolation and durability that makes the architecture reliable.
 
During failure recovery, we collect the state from all these sources and reconcile it into a consistent state using few simple rules. Lets look at how these rules play out in two scenarios - a failed database and a failed transaction coordinator. 

### Recovering from database failure

This is a case where the transaction coordinator lost contact with a database. The first order of business is to get back in touch. Unfortunately, Postgres does not have "database is back up" hook that we can use for a callback. Therefore both the coordinator and the `nile_ddl` extension periodically check the connection and attempt to reconnect if there is an issue. Once a connection is established, the transaction coordinator will check `pg_prepared_xact` and `distributed_transactions` tables on the recovering database. For every open transaction in the coordinator's in-memory state, the recovering DB can be in one of 3 states:

- Transaction committed successfuly. In this case, the coordinator just needs to update its in-memory state and the status tables in the metadata database. 
- Transaction prepared successfully but did not commit. In this case the coordinator checks the results of the transaction vote in its in-memory state, adding a "yes" vote from the recovered database. Based on the overall vote, the coordinator then decides if the transaction should commit or roll-back and distributes commands accordingly. 
- Transaction does not appear in either of the database state tables. This means that this database already rolled back the transaction, and it never successfully prepared. This means that the database voted "no" in the commit vote, and the transaction coordinator has to distribute `ROLLBACK PREPARED` to the other databases that participated in the transaction.

There is one special case for database failure, which is the case where the database where the transaction originated has failed. If you recall, this database is responsible for notifying the transaction coordinator that about the `XACT_EVENT_PRE_COMMIT` and `XACT_EVENT_COMMIT` events for the transaction. If the originating database fails, the coordinator may be stuck with an "orphan" transactions that never get prepared or committed. For this case, we rely on the transaction timeouts and a scheduled thread on the coordinator to roll back the orphaned transaction.

### Recovering from coordinator failure

If the coordinator itself fails, the first order of business is to reconstruct the in-memory state, so it will be aware of all the on-going transactions and capable of completing them. It first uses the latest state from the status tables in the metadata database, and then start checking state of individual databases.
For each transaction, each database can either have it in committed state, in prepared state, or not have it at all. This leads to a few possible scenarios:

- Transaction is in a committed state in all databases. In this case, we are done and can update the in-memory state and the status tables in the metadata database accordingly.
- Transaction is in prepared state in some databases and committed in others. This indicates that the vote was successful, but the commit wasn't fully distributed. The coordinator will distribute `COMMIT PREPARED` to the databases that are still in prepared state and complete the transaction.
- Transaction is in prepared state in some databases and does not exist in others. This indicates a failed vote. The databases where the transaction does not exist have rolled it back already. The coordinator will distribute `ROLLBACK PREPARED` to the remaining databases. 
- Transaction is in committed state in some databases and does not exist in others. This should never ever happen. If some databases committed, it indicates a unanimous vote to commit, but the databases without the transaction have voted "no" and rolled back. This shouldn't happen, and hasn't happened in months of both intensive testing and production use.


And thats it, our distributed DDL system can now handle any failure. You may be curious how we tested all this, but we'll leave that to another blog post.

## Sum things up

Its been quite a deep dive into the nooks and crannies of an architecture that overall isn't very complex, as far as distributed systems go.
Lets recap the main points:

Nile re-engineered Postgres for multi-tenant applications with out virtual tenant databases. Each virtual tenant database provides isolation and the flexibility to place, backup or branch the tenant's data independently. On the other hand, we preserve the developer experience of a single database and allow queries, including DDL across all tenant databases.

In order to preserve the normal behavior of DDLs across all tenants and multiple physical databases, we developed a distributed transaction architecture. This architecture consists of two key parts - transaction coordinator service and a Postgres extension.

We have shown how our extension hooks into the DDL processing flow via `processUtility_hook` and into the transaction lifecycle via the `XactCallback` and its events. We also showed how the extension can use lower level lock structures to achieve a locking behavior that we needed and wasn't exposed by high level Postgres commands.

We discussed how the transaction coordinator starts distributed transactions, distributes DDL and uses Postgres' existing transactions, their implementation and guarantees, to both commit the distributed transactions and handle failures. Our architecture benefits from relying on mechanisms and guarantees that have been battle-tested in production systems for over 35 years.

Finally, perhaps the biggest lesson we learned, is that while multi-tenant applications have been around for decades, their requirements are only partially addressed by most existing databases. This is great news because it means there are plenty of fun technical challenges to resolve for these applications. Reliably distributing DDLs is only one example for such requirement. Nile focuses on multi-tenant applications and their requirements, we can address those problems that every engineer knows about, but are rarely tackled systematically in the database. [Sign up to Nile](https://console.thenile.dev) and join us on this journey.