export const metadata = {
  title: "Voyage",
  order: 5,
};

# Voyage Embedding Models

## Availble models

Voyage has a collection of specialized models for embedding text from different domains: financial, legal 
(and large documents), code and medical.
It also has highly ranked general embedding model that can be used for a variety of tasks, 
a general model that is optimized for retrieval, and a smaller cost-efficient retrieval model.

We included a subset here for reference:

<table suppressHydrationWarning>
  <tr>
    <td>voyage-large-2-instruct</td>
    <td>1024</td>
    <td>16000</td>
    <td>$0.12 / 1M tokens</td>
    <td>68.28</td>
    <td>cosine, dot product, L2</td>
  </tr>
  <tr>
    <td>voyage-2</td>
    <td>1024</td>
    <td>4000</td>
    <td> $0.1/ 1M tokens</td>
    <td></td>
    <td>cosine, dot product, L2</td>
  </tr>
  <tr>
    <td>voyage-code-2</td>
    <td>1536</td>
    <td>16000</td>
    <td> $0.12/ 1M tokens</td>
    <td></td>
    <td>cosine, dot product, L2</td>
  </tr>
  <tr>
    <td>voyage-law-2</td>
    <td>1024</td>
    <td>16000</td>
    <td> $0.12/ 1M tokens</td>
    <td></td>
    <td>cosine, dot product, L2</td>
  </tr>
</table>

## Usage

Voyage has a Python, but not a Javascript, SDK. Their REST API is **almost** compatible with OpenAI's API, 
but unfortunately, their powerful general purpose model, `voyage-large-2-instruct` requires `inputType` parameter, 
which is not supported by OpenAI's SDK. So the example below will use the `voyage-large-2-instruct` with Javascript's
built-in `fetch` function. This makes the example code below quite verbose, but this is their only option for 
using the recommended model with Javascript.

If you use a different model, I recommend using the OpenAI SDK, with your Voyage API key and URL.
Also worth noting that LangChain has a nice JS library for Voyage, which supports the `inputType` parameter.

### Installing dependencies

```bash
npm install @niledatabase/server
```

### Generating embeddings with Voyage

```javascript
const VOYAGE_API_KEY = "your voyage api key";
const VOYAGE_URL = "https://api.voyageai.com/v1/embeddings";
const VOYAGE_HEADERS = {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${VOYAGE_API_KEY}`
  }
const model = "voyage-large-2-instruct"; // replace with your favorite cohere model

// this is the request for Voyage's API, for the document embedding
const document_body = JSON.stringify({
  input: [
    'The future belongs to those who believe in the beauty of their dreams.'
  ],
  model: model,
  input_type: 'document' // used for embeddings of documents stored in pg_vector
});

const doc_vec_resp = await fetch(VOYAGE_URL, {
  method: 'POST',
  headers: VOYAGE_HEADERS,
  body: document_body,
})

let doc_vec = []; // the document embedding will be here
if (doc_vec_resp.ok) {
    let doc_vec_json = await doc_vec_resp.json();
    // Voyage's response is an array of objects
    // each with a property 'embedding' that contains the vector
    doc_vec = doc_vec_json.data[0].embedding;
} else {
  // some error handling, watch out for rate limits and such
  let error = await doc_vec_resp.text();
  console.log(`HTTP error! 
    status: ${doc_vec_resp.status}
    error: ${error}`
  );
  process.exit(1);
}

// this is the request for Voyage's API, for the query embedding
const question_body = JSON.stringify({
  input: [
    "Who does the future belong to?"
  ],
  model: model,
  input_type: 'query'
});

const question_vec_resp = await fetch(VOYAGE_URL, {
  method: 'POST',
  headers: VOYAGE_HEADERS,
  body: document_body,
})

let question_vec = []; // the document embedding will be here
if (question_vec_resp.ok) {
    let question_vec_json = await question_vec_resp.json();
    // Voyage's response is an array of objects
    // each with a property 'embedding' that contains the vector
    question_vec = question_vec_json.data[0].embedding;
} else {
  // some error handling, watch out for rate limits and such
  let error = await question_vec_resp.text();
  console.log(`HTTP error! 
    status: ${question_vec_resp.status}
    error: ${error}`
  );
  process.exit(1);
}
```

### Storing and retrieving the embeddings

```javascript
// set up Nile as the vector store
const { Nile } = await import("@niledatabase/server");
const NILEDB_USER = "you need a nile user with access to a nile database";
const NILEDB_PASSWORD = "and a password for that user";
const nile = await Nile({
  user: NILEDB_USER,
  password: NILEDB_PASSWORD,
});

// store vector in a table
await nile.db.query("INSERT INTO embeddings (embedding) values ($1)", [
  JSON.stringify(doc_vec.map((v) => Number(v))),
]);

// search for similar vectors
let db_resp = await nile.db.query(
  "select embedding from embeddings order by embedding<=>$1 limit 1",
  [JSON.stringify(question_vec.map((v) => Number(v)))]
);

// Postgres returns an object, with array of rows each column is a
// property of the row the vector is represented as a string
let similar_str = db_resp.rows[0].embedding;
let similar = similar_str.
    substring(1, similar_str.length - 1).
    split(",").
    map((v) => parseFloat(v));

// check that we got the same vector back
let same = true;

for (let i = 0; i < similar.length; i++) {
  if (Math.abs(similar[i] - doc_vec[i]) > 0.000001) {
    same = false;
  }
}

console.log("got same vector? " + same);
```

## Additional information
### Distance metrics

Voyage embeddings are normalized to length 1, which means that you can use L2, cosine, and dot product similarity 
metrics interchangeably. Dot product is the fastest to compute.

### API Rate limits

Note that on the free plan, the rate limits are quite strict. Voyage gives you only 3 API calls a minute.
Which means that after you embedded some documents, you can only generate embeddings for 2 queries before 
running out of the minute and having to wait.
