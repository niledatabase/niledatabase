# fly.toml app configuration file generated for prisma-demo on 2024-01-02T08:40:35-08:00
#
# See https://fly.io/docs/reference/configuration/ for information about how to use this file.
#

app = "prisma-demo"
primary_region = "sjc"

[build]

[env]
  REQUIRE_AUTH=true
  AI_BASE_URL="https://api.fireworks.ai/inference/v1"
  AI_MODEL="accounts/fireworks/models/llama-v3p1-405b-instruct"
  EMBEDDING_MODEL="nomic-ai/nomic-embed-text-v1.5"


[http_service]
  internal_port = 3001
  force_https = true
  auto_stop_machines = false
  auto_start_machines = true
  min_machines_running = 0
  processes = ["app"]

[[vm]]
  cpu_kind = "shared"
  cpus = 1
  memory_mb = 512


